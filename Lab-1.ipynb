{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293732c8",
   "metadata": {},
   "source": [
    "# Lab Assigment 1\n",
    "## DS 6600: Data Engineering 1\n",
    "##### Andres Castellanos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29cbf9",
   "metadata": {},
   "source": [
    "## Problem 1:\n",
    "\n",
    "I created a new GitHub repository in which the URL is below:\n",
    "\n",
    "https://github.com/CastelAndres/DS6600_lab1.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f69ed7",
   "metadata": {},
   "source": [
    "## Problem 2:\n",
    "\n",
    "\n",
    "Describe, in words, whether a virtual machine, a container, a virtual environment, or the global environment of a single computer is best suited for each of the following situations. Be clear about why the option you choose works best, and also about why the other options are insufficient or are overkill.\n",
    "\n",
    " - a. For the scenario of Meals on Wheels a Container is the best option. I recall that a great benefit of using containers is that it will let you \"package\" the web portal and mobile app so that it runs identical for ANY chapter, regardless of hardware. This also allows the current data base to be connected to each new container for each new chapter created, which containers are also easily scalable. \n",
    "  A virtual machine wont be the best option as it provides isolation, which means that duplicating full OS images for EVERY new chapter will come with a price and will be resource intensive.\n",
    "  A virtual environment will only isolate Python packages, which is not sufficient to manage their apps,databases, and website.\n",
    "  Lastly, the global environment would basically be stuck sharing one system. This would be a nightmare to manage as it would be hard to separate volunteer and client data securely, and scaling would be really hard.\n",
    "\n",
    " - b. In this scenario the Legal Aid Justice Center would be better off using a virtual environment as they're dealing with a data cleaning task. A Python virtual environment such as pandas, will pretty much allow you to clean the data. This virtual environment also allows for isolation of the project dependencies. Another great perk as to why its a great option is that once you have cleaned the data, you can easily export what you need and wont have to worry about hosting/deployment. \n",
    "  A container in this situation is possible, but overkill, since the task requires just a one-time report you wont have to worry about a reproducible service/app.\n",
    "  A virtual machine would just be a waste of time and resources to run a whole extra OS to process just this single task.\n",
    "  A Global environment would work as well, but the issue become when your system Python environment gets cluttered with various analysis libraries. The virtual environment keeps things cleaner/easier to reproduce if you need to do so later.\n",
    "\n",
    " - c. For this task it appears that a container would be best suited. Since we need Ubuntu system packages the container would let us build an image that installs the necessary packages and our Python environment as well. This makes it so we are not forcing others to run full Ubunty VM's or change their OS. This also allows for distribution options and allows us to have controlled dependencies.\n",
    "  A virtual machine could run Ubunty, but it is slower to start and makes it harder to distribute when compared to containers.\n",
    "  A virtual environment is only able to manage Python libraries and cant handle the Ubuntu system dependencies the packages require.\n",
    "  Lastly, the global environment wouldn't work if someone isn't on Ubunty, this will lead to conflicts in installing the necessary packages.\n",
    "  \n",
    " - d. A virtual environment seems best suitable for this scenario since the virtual environment will lock our project to Python 3 and its packages. This means that even if Python 4 is installed globally, our current project will still be able to run with Python 3 environment. This allows us to keep projects separate, so we can have on project using Python 3 and another using Python 4.\n",
    "  A container does work, but it overkill if the only goal is to preserve a single Python version.\n",
    "  A virtual machine is just using too much resources and overkill to spin up a whole other OS just to preserve a Python version.\n",
    "  Lastly a global environment wont work since if you decide to upgrade to Python 4, the projects with Python 3 will break.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a359f77",
   "metadata": {},
   "source": [
    "## Problem 3:\n",
    "\n",
    "### Problem 3a.\n",
    "\n",
    "Created a conda environemnet with Python 3.12 and installed the following packages:\n",
    "- conda create -n lab1 python=3.12\n",
    "- conda activate lab1\n",
    "- conda install neo4j\n",
    "- conda install python-dotenv\n",
    "- conda install pandas\n",
    "- conda install numpy #was already installed\n",
    "- conda install scipy\n",
    "- conda install scikit-learn\n",
    "- conda install requests\n",
    "- conda install prince\n",
    "- conda install ipykernel\n",
    "- conda install conda-forge::wquantiles \n",
    "- pip install ydata_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6143595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import weighted # this is a module of wquantiles\n",
    "from scipy import stats\n",
    "import prince\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc53df5",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "The official Python images on Docker Hub use a version of Linux called Debian.However, sometimes you might need to install additional software in a container other than Python and Python packages, and a lot of open source software only works on another version of Linux called Ubuntu.\n",
    "\n",
    "### Part a.\n",
    "\n",
    "Below is a Dockerfile that builds an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9914fa6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4121029849.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mFROM ubuntu:latest\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Start from the latest Ubuntu image\n",
    "FROM ubuntu:latest\n",
    "\n",
    "# Update package lists & install Python 3\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y python3 && \\\n",
    "    apt-get clean\n",
    "\n",
    "#Set the working directory inside the container\n",
    "WORKDIR /app\n",
    "\n",
    "#Copy local files into the container\n",
    "COPY . /app\n",
    "\n",
    "#By default, launch Python 3\n",
    "CMD [\"python3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876e605",
   "metadata": {},
   "source": [
    "### Part b.\n",
    "\n",
    "Proving that the Dockerfile is written correctly by building the image associated with this\n",
    "Dockerfile. Below is the output of the build from my terminal: \n",
    "Note: The image is titled \"lab1-image\"\n",
    "\n",
    "- REPOSITORY                      TAG       IMAGE ID       CREATED          SIZE\n",
    "- lab1-image                      latest    05f9921b4ffb   30 seconds ago   299MB\n",
    "- chandres/jupyterdocker          latest    d5ec3507b9c9   2 weeks ago      3.36GB\n",
    "- chandres/python_jupyterdocker   latest    d5ec3507b9c9   2 weeks ago      3.36GB\n",
    "- jupyterdocker                   latest    d5ec3507b9c9   2 weeks ago      3.36GB\n",
    "- mysql                           latest    94254b456a6d   2 weeks ago      1.27GB\n",
    "- postgres                        latest    feff5b24fedd   2 weeks ago      662MB\n",
    "- mongo                           latest    cf340b1e5283   2 weeks ago      1.2GB\n",
    "\n",
    "I also got the output below when building the image from the terminal (this was the output prior to the one above):\n",
    "\n",
    "[+] Building 0.5s (9/9) FINISHED                                                                        docker:desktop-linux\n",
    " => [internal] load build definition from Dockerfile                                                                    0.0s\n",
    " => => transferring dockerfile: 374B                                                                                    0.0s\n",
    " => [internal] load metadata for docker.io/library/ubuntu:latest                                                        0.4s\n",
    " => [internal] load .dockerignore                                                                                       0.0s\n",
    " => => transferring context: 2B                                                                                         0.0s\n",
    " => [1/4] FROM docker.io/library/ubuntu:latest@sha256:353675e2a41babd526e2b837d7ec780c2a05bca0164f7ea5dbbd433d21d166fc  0.0s\n",
    " => => resolve docker.io/library/ubuntu:latest@sha256:353675e2a41babd526e2b837d7ec780c2a05bca0164f7ea5dbbd433d21d166fc  0.0s\n",
    " => [internal] load build context                                                                                       0.0s\n",
    " => => transferring context: 14.19kB                                                                                    0.0s\n",
    " => CACHED [2/4] RUN apt-get update &&     apt-get install -y python3 &&     apt-get clean                              0.0s\n",
    " => CACHED [3/4] WORKDIR /app                                                                                           0.0s\n",
    " => [4/4] COPY . /app                                                                                                   0.0s\n",
    " => exporting to image                                                                                                  0.1s\n",
    " => => exporting layers                                                                                                 0.0s\n",
    " => => exporting manifest sha256:be5bd1ec956001af83b30fe83055df0aa5089f34f7db32d6457e129aae0af321                       0.0s\n",
    " => => exporting config sha256:d8ab6517f4f61d71d75780b0d0a1da353664fe24b0c19728758d7e56046b7c62                         0.0s\n",
    " => => exporting attestation manifest sha256:ad4043f0541fb17b7ccbc796b5cd8b3acbae48b8c26b5c73aca92ce732bc062d           0.0s\n",
    " => => exporting manifest list sha256:8b1c39aa1c8f4b7d65155e9dfc2e5d9deebfbcecac0370d3bbbf4afcd3915fa3                  0.0s\n",
    " => => naming to docker.io/library/lab1-image:latest                                                                    0.0s\n",
    " => => unpacking to docker.io/library/lab1-image:latest                                                                 0.0s\n",
    "\n",
    "View build details: docker-desktop://dashboard/build/desktop-linux/desktop-linux/6djciu7txzwci6hbcp62etxmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350939f",
   "metadata": {},
   "source": [
    "### Part c.\n",
    "\n",
    "Below is my conifrmation that the Python Prompt appears correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c63858",
   "metadata": {},
   "outputs": [],
   "source": [
    "(base) andrescastellanos@Andress-MacBook-Air DS6600_lab1 % docker run -it lab1-image\n",
    "\n",
    "Python 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0] on linux\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870495f",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Below is the passage from the docker image running Nethack:\n",
    "\n",
    "\n",
    "\"It is written in the Book of Hermes:\n",
    "\n",
    "    After the Creation, the cruel god Moloch rebelled\n",
    "    against the authority of Marduk the Creator.\n",
    "    Moloch stole from Marduk the most powerful of all\n",
    "    the artifacts of the gods, the Amulet of Yendor,\n",
    "    and he hid it in the dark cavities of Gehennom, the\n",
    "    Under World, where he now lurks, and bides his time.\n",
    "\n",
    "Your god Hermes seeks to possess the Amulet, and with it\n",
    "to gain deserved ascendance over the other gods.\n",
    "\n",
    "You, a newly trained Rhizotomist, have been heralded\n",
    "from birth as the instrument of Hermes.  You are destined\n",
    "to recover the Amulet for your deity, or die in the\n",
    "attempt.  Your hour of destiny has come.  For the sake of your god, you must descend into the depths of Gehennom, face its horrors, and retrieve the Amulet of Yendor. Only then can you ascend to the heavens and join your deity in eternal glory.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a9dea7",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "We've discussed connecting to MySQL, PostgreSQL, and Mongo using Docker, but there are many different kinds of database systems for different situations, and as a data scientist who can hang with the data engineers, you will need to be able to set up a\n",
    "database from a system you haven't used before. For this problem, use your Docker skills and your navigation of available documentation to create a local Python connection to a graph database running on Neo4j. See this [AWS blog[(https://aws.amazon.com/compare/the-difference-between-graph-and-relational-database/)] or the textbook for a deeper discussion of graph databases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f776911",
   "metadata": {},
   "source": [
    "### Part a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8880c",
   "metadata": {},
   "source": [
    "### Part B.\n",
    "\n",
    "- The Default ports are the following: \n",
    "    - Bolt Port: 7687\n",
    "    - HTTP Port: 7474\n",
    "  \n",
    "  These ports were found in the Docker Hub official Neo4j image page, under the \"How to use this image\" section. \n",
    "\n",
    "- Data folder inside the container: /data\n",
    "\n",
    "  These were found in the same docker hub page, in the same section if you read below the code example you will start to read about volumes. This will list /data  as the internal storage folder. \n",
    "\n",
    "- For environmental variables you need to set the NEO4J_AUTH variable to the value of username/password. \n",
    "  \n",
    "   - EX: --env NEO4J_AUTH=neo4j/your_password\n",
    "  \n",
    "  If you are working in an enterprise edition you would need the following:\n",
    "\n",
    "    - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes\n",
    "\n",
    "  This was also found in the same docker hub page under the \"Getting Started with Docker\" page. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c49b98",
   "metadata": {},
   "source": [
    "### Part C. Docker compose file for Neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c717f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1044058062.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mservices:\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "services:\n",
    "  neo4j:\n",
    "    image: neo4j:latest\n",
    "    container_name: neo4j\n",
    "    ports:\n",
    "      - \"7474:7474\"   # HTTP \n",
    "      - \"7687:7687\"   # Bolt \n",
    "    env_file:\n",
    "      - .env          # Load environment variables from .env\n",
    "    volumes:\n",
    "      - neo4jdata:/data\n",
    "\n",
    "volumes:\n",
    "  neo4jdata:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217ae20",
   "metadata": {},
   "source": [
    "### Part D. Launching the Neo4j container to become a rockstar engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a058cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: neo4j, Password: BOJACK123\n",
      "Connection to Neo4j established successfully.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Neo4j credentials from environment variable\n",
    "NEO4J_AUTH = os.getenv('NEO4J_AUTH').split('/')\n",
    "URI = 'bolt://localhost:7687'\n",
    "USERNAME = NEO4J_AUTH[0]\n",
    "PASSWORD = NEO4J_AUTH[1]\n",
    "\n",
    "# Print credentials for debugging\n",
    "print(f'Username: {USERNAME}, Password: {PASSWORD}')\n",
    "\n",
    "try:\n",
    "    # Create a Driver instance\n",
    "    driver = GraphDatabase.driver(URI, auth=(USERNAME, PASSWORD))\n",
    "    \n",
    "    # Verify connectivity immediately\n",
    "    driver.verify_connectivity()\n",
    "    print('Connection to Neo4j established successfully.')\n",
    "except Exception as e:\n",
    "    print(f'Failed to connect to Neo4j: {e}')\n",
    "finally:\n",
    "    # Close the driver to release resources\n",
    "    if 'driver' in locals() and driver:\n",
    "        driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
